{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import os\n",
        "from torch.utils.data import DataLoader\n",
        "import torch\n",
        "from torch.utils.data import random_split\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "U7DHTuPgyLl_"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DEVICE = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
      ],
      "metadata": {
        "id": "pjKYKDJZzn4x"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading FMNIST dataset"
      ],
      "metadata": {
        "id": "V-lfvSFK2u1y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_kfXGM3cx-tj",
        "outputId": "aef7c9fe-fe05-4267-c804-9c81ecd4be39"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to /content/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26421880/26421880 [00:02<00:00, 9435415.34it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /content/FashionMNIST/raw/train-images-idx3-ubyte.gz to /content/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to /content/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29515/29515 [00:00<00:00, 169839.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /content/FashionMNIST/raw/train-labels-idx1-ubyte.gz to /content/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to /content/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4422102/4422102 [00:01<00:00, 3100223.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /content/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to /content/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to /content/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5148/5148 [00:00<00:00, 14901502.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /content/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to /content/FashionMNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "fmnist_train = torchvision.datasets.FashionMNIST(os.getcwd(), train=True, download=True, transform=transforms.ToTensor())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loader = DataLoader(fmnist_train,\n",
        "                         batch_size=10,\n",
        "                         num_workers=0,\n",
        "                         shuffle=True)\n",
        "\n",
        "channels_sum, channels_squared_sum, num_batches = 0, 0, 0\n",
        "\n",
        "for data, _ in loader:\n",
        "    channels_sum += torch.mean(data, dim=[0, 2, 3])\n",
        "    channels_squared_sum += torch.mean(data**2, dim=[0, 2, 3])\n",
        "    num_batches += 1\n",
        "\n",
        "mean = channels_sum/num_batches\n",
        "std = (channels_squared_sum/num_batches - mean**2)**0.5\n",
        "print(mean, std)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tw3LMS8ix_m8",
        "outputId": "830981b1-026b-43a9-8ec5-89fafbf0bedc"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.2860]) tensor([0.3530])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.2860, ), (0.3530, ))])"
      ],
      "metadata": {
        "id": "2qWWRjCrypIc"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fmnist_train = torchvision.datasets.FashionMNIST(os.getcwd(), train=True, download=True, transform=transform)\n",
        "fmnist_test = torchvision.datasets.FashionMNIST(os.getcwd(), train=False, download=True, transform=transform)"
      ],
      "metadata": {
        "id": "y-9TF9Ntypx1"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fmnist_train, fmnist_val = random_split(fmnist_train, [55000, 5000])"
      ],
      "metadata": {
        "id": "Fvv70kCczDBr"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fmnist_train = DataLoader(fmnist_train, batch_size=64, num_workers=4, pin_memory=True, shuffle=True)\n",
        "fmnist_val = DataLoader(fmnist_val, batch_size=64, num_workers=4, pin_memory=True, shuffle=True)\n",
        "fmnist_test = DataLoader(fmnist_test, batch_size=64, num_workers=4, pin_memory=True, shuffle=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a2j6LUVTzHWm",
        "outputId": "f5cf9d75-9460-4f14-c902-a89e3e424935"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Defining network"
      ],
      "metadata": {
        "id": "rSH78vB-21pE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "  def __init__(self):\n",
        "      super().__init__()\n",
        "      self.conv1 = nn.Conv2d(1, 64, 3, 1)\n",
        "      self.conv2 = nn.Conv2d(64, 128, 3, 1)\n",
        "      self.dropout = nn.Dropout(p=0.5)\n",
        "      self.fc1 = nn.Linear(3200, 128)\n",
        "      self.fc2 = nn.Linear(128, 10)\n",
        "\n",
        "  def forward(self, x):\n",
        "      x = F.relu(self.conv1(x))\n",
        "      x = F.max_pool2d(x, 2, 2)\n",
        "      x = F.relu(self.dropout(self.conv2(x)))\n",
        "      x = F.max_pool2d(x, 2, 2)\n",
        "      x = x.view(-1, 3200)\n",
        "      x = F.relu(self.fc1(x))\n",
        "      x = self.fc2(x)\n",
        "      return x"
      ],
      "metadata": {
        "id": "SrgOxdOVzQF4"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Net()\n",
        "model = model.to(DEVICE)"
      ],
      "metadata": {
        "id": "fmZwIwrWzjon"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.RMSprop(model.parameters(), lr = 1e-3)"
      ],
      "metadata": {
        "id": "GQVdxELTzwQP"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchsummary import summary\n",
        "summary(model, input_size=(1, 28, 28))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lL5gOk7xz580",
        "outputId": "f5826eb3-86af-49fd-c86f-448446d601ac"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 26, 26]             640\n",
            "            Conv2d-2          [-1, 128, 11, 11]          73,856\n",
            "           Dropout-3          [-1, 128, 11, 11]               0\n",
            "            Linear-4                  [-1, 128]         409,728\n",
            "            Linear-5                   [-1, 10]           1,290\n",
            "================================================================\n",
            "Total params: 485,514\n",
            "Trainable params: 485,514\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.57\n",
            "Params size (MB): 1.85\n",
            "Estimated Total Size (MB): 2.42\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Helper functions"
      ],
      "metadata": {
        "id": "sE8cr9u427bg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def common_compute(model, batch):\n",
        "    x, y = batch\n",
        "    x, y = x.to(DEVICE), y.to(DEVICE)\n",
        "    logits = model(x)\n",
        "    loss = F.cross_entropy(logits, y)\n",
        "    return logits, loss, y"
      ],
      "metadata": {
        "id": "P7N-jXQ60MB7"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_batch(model, optimizer, batch):\n",
        "    logits, loss, _ = common_compute(model, batch)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "    return loss"
      ],
      "metadata": {
        "id": "Z126tH1V0OxW"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def validate_batch(model, batch):\n",
        "    logits, loss, _ = common_compute(model, batch)\n",
        "    return loss"
      ],
      "metadata": {
        "id": "0Kcxdoo30QUx"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_batch(model, batch):\n",
        "    logits, loss, y = common_compute(model, batch)\n",
        "    _, predicted = torch.max(logits.data, 1)\n",
        "    return y.size(0), (predicted == y).sum().item(), loss"
      ],
      "metadata": {
        "id": "B-3vWkZu0S2e"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training loop"
      ],
      "metadata": {
        "id": "EskT-aRL2-nr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 15\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    train_loss = []\n",
        "    bar = tqdm(fmnist_train, position=0, leave=False, desc='epoch %d'%epoch)\n",
        "    for batch in bar:\n",
        "        loss = train_batch(model, optimizer, batch)\n",
        "        train_loss.append(loss)\n",
        "    avg_train_loss = torch.stack(train_loss).mean()\n",
        "    print('train_loss', avg_train_loss.item())\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        val_loss = []\n",
        "        for batch in fmnist_val:\n",
        "            loss = validate_batch(model, batch)\n",
        "            val_loss.append(loss)\n",
        "        avg_val_loss = torch.stack(val_loss).mean()\n",
        "        print('val_loss', avg_val_loss.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XrxEvqC30UjE",
        "outputId": "22a0748b-de0a-4d73-c9d6-e62c5ab47722"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                          "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_loss 0.5687328577041626\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val_loss 0.38607266545295715\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                          "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_loss 0.3502223789691925\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val_loss 0.359352707862854\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                          "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_loss 0.3020690083503723\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val_loss 0.30992591381073\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                          "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_loss 0.275563508272171\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val_loss 0.3165651857852936\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                          "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_loss 0.25584250688552856\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val_loss 0.2598448693752289\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                          "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_loss 0.2413945347070694\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val_loss 0.27394595742225647\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                          "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_loss 0.22929425537586212\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val_loss 0.24525509774684906\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_loss 0.21992388367652893\n",
            "val_loss 0.23827221989631653\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                          "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_loss 0.2107696533203125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val_loss 0.2359306961297989\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                          "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_loss 0.201670840382576\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val_loss 0.2358035147190094\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                           "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_loss 0.19287459552288055\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val_loss 0.23590590059757233\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                           "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_loss 0.18770372867584229\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val_loss 0.22306309640407562\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                           "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_loss 0.181253582239151\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val_loss 0.2175786942243576\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                           "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_loss 0.1767544001340866\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val_loss 0.22451826930046082\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                           "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_loss 0.16948078572750092\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val_loss 0.2429293692111969\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing"
      ],
      "metadata": {
        "id": "ZfhGVY-W3BNP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bar = tqdm(fmnist_test, position=0, leave=False, desc='test')\n",
        "test_loss = []\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for batch in bar:\n",
        "        batch_size, batch_correct, loss = test_batch(model, batch)\n",
        "        total += batch_size\n",
        "        correct += batch_correct\n",
        "        test_loss.append(loss)\n",
        "    avg_test_loss = torch.stack(test_loss).mean()\n",
        "    print('test_loss', avg_test_loss.item())\n",
        "    print('Accuracy %.2f%%' % (100 * float(correct) / total))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b73FSRyp1KeH",
        "outputId": "52a809b3-a7ee-43ab-effb-a770a25be9a3"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                       "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test_loss 0.25632283091545105\n",
            "Accuracy 91.00%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model, 'model_fmnist.pth')"
      ],
      "metadata": {
        "id": "Z-KiYZj11Pge"
      },
      "execution_count": 19,
      "outputs": []
    }
  ]
}